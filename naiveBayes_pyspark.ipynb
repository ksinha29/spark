{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "findspark.find()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"NaiveBayes\")\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = spark.read.csv(\"diabetes.csv\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "|          6|    148|           72|           35|      0|33.6|                   0.627| 50|      1|\n",
      "|          1|     85|           66|           29|      0|26.6|                   0.351| 31|      0|\n",
      "|          8|    183|           64|            0|      0|23.3|                   0.672| 32|      1|\n",
      "|          1|     89|           66|           23|     94|28.1|                   0.167| 21|      0|\n",
      "|          0|    137|           40|           35|    168|43.1|                   2.288| 33|      1|\n",
      "|          5|    116|           74|            0|      0|25.6|                   0.201| 30|      0|\n",
      "|          3|     78|           50|           32|     88|  31|                   0.248| 26|      1|\n",
      "|         10|    115|            0|            0|      0|35.3|                   0.134| 29|      0|\n",
      "|          2|    197|           70|           45|    543|30.5|                   0.158| 53|      1|\n",
      "|          8|    125|           96|            0|      0|   0|                   0.232| 54|      1|\n",
      "|          4|    110|           92|            0|      0|37.6|                   0.191| 30|      0|\n",
      "|         10|    168|           74|            0|      0|  38|                   0.537| 34|      1|\n",
      "|         10|    139|           80|            0|      0|27.1|                   1.441| 57|      0|\n",
      "|          1|    189|           60|           23|    846|30.1|                   0.398| 59|      1|\n",
      "|          5|    166|           72|           19|    175|25.8|                   0.587| 51|      1|\n",
      "|          7|    100|            0|            0|      0|  30|                   0.484| 32|      1|\n",
      "|          0|    118|           84|           47|    230|45.8|                   0.551| 31|      1|\n",
      "|          7|    107|           74|            0|      0|29.6|                   0.254| 31|      1|\n",
      "|          1|    103|           30|           38|     83|43.3|                   0.183| 33|      0|\n",
      "|          1|    115|           70|           30|     96|34.6|                   0.529| 32|      1|\n",
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Pregnancies: string (nullable = true)\n",
      " |-- Glucose: string (nullable = true)\n",
      " |-- BloodPressure: string (nullable = true)\n",
      " |-- SkinThickness: string (nullable = true)\n",
      " |-- Insulin: string (nullable = true)\n",
      " |-- BMI: string (nullable = true)\n",
      " |-- DiabetesPedigreeFunction: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- Outcome: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "new_data = dataset.select(*(col(c).cast(\"float\").alias(c) for c in dataset.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Pregnancies: float (nullable = true)\n",
      " |-- Glucose: float (nullable = true)\n",
      " |-- BloodPressure: float (nullable = true)\n",
      " |-- SkinThickness: float (nullable = true)\n",
      " |-- Insulin: float (nullable = true)\n",
      " |-- BMI: float (nullable = true)\n",
      " |-- DiabetesPedigreeFunction: float (nullable = true)\n",
      " |-- Age: float (nullable = true)\n",
      " |-- Outcome: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-------------+-------------+-------+---+------------------------+---+-------+\n",
      "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin|BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
      "+-----------+-------+-------------+-------------+-------+---+------------------------+---+-------+\n",
      "|          0|      0|            0|            0|      0|  0|                       0|  0|      0|\n",
      "+-----------+-------+-------------+-------------+-------+---+------------------------+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count, isnan, when\n",
    "#checking for null ir nan type values in our columns\n",
    "new_data.select([count(when(col(c).isNull(), c)).alias(c) for c in new_data.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=new_data.columns\n",
    "cols.remove(\"Outcome\")\n",
    "assembler = VectorAssembler(inputCols=cols,outputCol=\"features\")\n",
    "# Now let us use the transform method to transform our dataset\n",
    "data=assembler.transform(new_data)\n",
    "data = data.select(\"features\",'Outcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train, test) = data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes = NaiveBayes(featuresCol='features',labelCol='Outcome',smoothing=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = naive_bayes.fit(train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select example rows to display.\n",
    "predictions = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+--------------------+--------------------+----------+\n",
      "|            features|Outcome|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-------+--------------------+--------------------+----------+\n",
      "|(8,[1,5,6,7],[117...|    0.0|[-323.61224216275...|[0.09454563319014...|       1.0|\n",
      "|(8,[1,5,6,7],[138...|    1.0|[-307.81086275721...|[0.01681026466627...|       1.0|\n",
      "|(8,[1,5,6,7],[145...|    1.0|[-346.93881460780...|[0.02407280353738...|       1.0|\n",
      "|[0.0,67.0,76.0,0....|    0.0|[-417.06677625264...|[0.99999931459960...|       0.0|\n",
      "|[0.0,74.0,52.0,10...|    0.0|[-370.58046002135...|[0.99276890812465...|       0.0|\n",
      "|[0.0,84.0,64.0,22...|    0.0|[-499.12358955402...|[0.99356710387183...|       0.0|\n",
      "|[0.0,84.0,82.0,31...|    0.0|[-651.79943709385...|[0.93393807821312...|       0.0|\n",
      "|[0.0,91.0,80.0,0....|    0.0|[-376.62699782289...|[0.99999309663815...|       0.0|\n",
      "|[0.0,93.0,60.0,25...|    0.0|[-536.09847424452...|[0.69234538911861...|       0.0|\n",
      "|[0.0,94.0,70.0,27...|    0.0|[-626.03561286090...|[0.70974456634911...|       0.0|\n",
      "|[0.0,95.0,85.0,25...|    1.0|[-516.57415694158...|[0.99999502583848...|       0.0|\n",
      "|[0.0,98.0,82.0,15...|    0.0|[-526.74439146594...|[0.96942603437151...|       0.0|\n",
      "|[0.0,101.0,76.0,0...|    0.0|[-384.26388957899...|[0.99998053043848...|       0.0|\n",
      "|[0.0,102.0,52.0,0...|    0.0|[-308.67933125842...|[0.99730238628169...|       0.0|\n",
      "|[0.0,102.0,78.0,4...|    0.0|[-630.63524263522...|[0.99815764574379...|       0.0|\n",
      "|[0.0,104.0,64.0,2...|    0.0|[-585.58987043937...|[0.08985496676119...|       1.0|\n",
      "|[0.0,104.0,76.0,0...|    0.0|[-350.87657610932...|[0.99993225333678...|       0.0|\n",
      "|[0.0,107.0,60.0,2...|    0.0|[-405.23260845072...|[0.99998171863247...|       0.0|\n",
      "|[0.0,107.0,76.0,0...|    0.0|[-412.58602163743...|[0.99998294811699...|       0.0|\n",
      "|[0.0,109.0,88.0,3...|    1.0|[-521.56064880387...|[0.99999996502623...|       0.0|\n",
      "+--------------------+-------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "labelCol=\"Outcome\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.6697674418604651\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
